#!/usr/bin/env python

__usage__ = "investigate [--options]"
__doc__ = "run the playground investigation for kde-inversion sanity"
__author__ = "Reed Essick (reed.essick@ligo.org)"

#-------------------------------------------------

import os

import numpy as np

import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt

from optparse import OptionParser

from kde_inv import kde_inv

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')

parser.add_option('-n', '--num-samples', default=1000, type='int',
    help='DEFAULT=1000')
parser.add_option('-N', '--num-samples-recovery', default=1000, type='int',
    help='DEFAULT=1000')

#parser.add_option('', '--num-test', default=100, type='int', 
#    help='the number of samples used as the validation set in leave1outLikelihood. \
#DEFAULT=100')
#parser.add_option('', '--num-trials', default=1000, type='int',
#    help='the number of trials over which we average in leave1outLikelihood. \
#DEFAULT=1000')
#parser.add_option('', '--rtol', default=1e-3, type='float',
#    help='tolerance used in numeric optimzation of bandwidth. \
#DEFAULT=1e-6')

parser.add_option('', '--bandwidth', default=1e-3, type='float',
    help='the bandwidth used when attempting to recover p(A) from samples~p(B)')

parser.add_option('', '--num-plot', default=1001, type='int',
    help='the number of evaluation points used to produce KDE p(B) plot. \
DEFAULT=1001')
parser.add_option('', '--colormap', default='jet', type='string')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

opts, args = parser.parse_args()

if opts.tag:
    opts.tag = "_"+opts.tag

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

#-------------------------------------------------

### sample from p(A)
if opts.verbose:
    print('drawing %d samples from p(A)'%opts.num_samples)
A = kde_inv.drawA(size=opts.num_samples)

# generate figure
fig = plt.figure()
ax = fig.gca()

ax.scatter(A[0], A[1], alpha=0.25, s=1)
ax.set_xlabel('A[0]')
ax.set_ylabel('A[1]')

ax.set_xlim(xmin=0, xmax=1)
ax.set_ylim(ymin=0, ymax=1)

ax.grid(True, which='both')

figname = "%s/samples_A%s.png"%(opts.output_dir, opts.tag)
if opts.verbose:
    print('    '+figname)
fig.savefig(figname)
plt.close(fig)

#------------------------

### compute values of B
if opts.verbose:
    print('computing B=mapA2B(A)')
B = kde_inv.mapA2B(A)

# generate histogram
fig = plt.figure()
ax = fig.gca()

ax.hist(B, bins=int(opts.num_samples**0.5), histtype='step', weights=np.ones_like(B, dtype=float)/opts.num_samples)
ax.set_xlabel('B')
ax.set_ylabel('fraction of samples')

ax.set_xlim(xmin=0, xmax=2)

ax.grid(True, which='both')

figname = '%s/histogram_B%s.png'%(opts.output_dir, opts.tag)
if opts.verbose:
    print('    '+figname)
fig.savefig(figname)

#------------------------

### find optimal bandwidth
if opts.verbose:
    print('generating likelihood vs. bandwidth plot')
bandwidths = [
    1e-5,
    3e-5,
    1e-4,
    3e-4,
    1e-3,
    3e-3,
    1e-2,
    3e-2,
    1e-1,
    3e-1,
#    1e0,
]
#fig = kde_inv.likelihood_plot(B, bandwidths, opts.num_test, opts.num_trials, opts.num_plot, verbose=opts.verbose)
fig = kde_inv.explicit_likelihood_plot(np.concatenate((B, -B, 4-B)), bandwidths, opts.num_plot, verbose=opts.verbose)
figname = '%s/likelihood%s.png'%(opts.output_dir, opts.tag)
if opts.verbose:
    print('    '+figname)
fig.savefig(figname)
plt.close(fig)

#------------------------

### try to recover p(A) via kde_inversion
if opts.verbose:
    print('computing the measure associated with mapping A->B\nEssentially, an over-counting factor associated with mapping multiple values of A into the same value of B')
Asamples = kde_inv.drawA(opts.num_samples_recovery)

Bsamples = np.random.random(opts.num_samples)*2 ### just draw uniformly from the B distribution...
#Bsamples = B[:]

### enforce periodic/reflecting boundary conditions
Bsamples = np.concatenate((Bsamples, -Bsamples, 4-Bsamples))

weights = np.exp(kde_inv.compute_weights(Asamples, Bsamples, opts.bandwidth))

m=np.min(weights)
M=np.max(weights)
dM=M-m
if opts.verbose:
    print('    min(weights)=%.3e'%m)
    print('    max(weights)=%.3e'%M)

# generate figure
if opts.verbose:
    print('plotting...')
fig = plt.figure()
ax = fig.gca()

cmap = plt.get_cmap(opts.colormap)
for a, weight in zip(Asamples.transpose(), weights):
    ax.scatter(a[0], a[1], color=cmap((weight-m)/dM), s=1)
ax.set_xlabel('A[0]')
ax.set_ylabel('A[1]')

ax.set_xlim(xmin=0, xmax=1)
ax.set_ylim(ymin=0, ymax=1)

ax.grid(True, which='both')

figname = "%s/measure_A%s.png"%(opts.output_dir, opts.tag)
if opts.verbose:
    print('    '+figname)
fig.savefig(figname)
plt.close(fig)

#------------------------

### compute distance from known distribution...
raise NotImplementedError, '''\
try to recover a distribution over A assuming L(data|B)~constant
    should reproduce p(A), compare with kde_inv.kldiv

 -> draw more samples: A_i~p(A)
 -> for each A_i~p(A), compute B_i = mapA2B(A_i)
        compute w_i = KDE(B_i, B_j~p(B); bandwidth) (and store it in association with A_i)
 -> look at the distribution of w_i in A-space (a plot)
   -> scatter plot in A-space with alpha-values weighted by w_i?
   -> weighted 2-D histogram in A-space?
   -> weighted KDE histogram in A-space?
 -> compute KL divergence between known function for p(A) and recovered estimate based on w_i
'''

#------------------------

### implement some non-trivial likelihood over B and infer the posterior over A
if opts.verbose:
    print('attempting to recover p(A|data) from samples~p(B|data) and KDE with bandwidth=%.3e'%bandwidth)
raise NotImplementedError, '''\
implement some non-trivial likelihood over B (a relatively narrow Guassian?) and infer the posterior over A
    try a relatively tight Gaussian in B as the likelihood -> should pick out a sinusoidal region of A-space
    sample from this, don't use the analytic result
    compare this to the posterior achieved via direct sampling (grid based? MCMC?)
'''
